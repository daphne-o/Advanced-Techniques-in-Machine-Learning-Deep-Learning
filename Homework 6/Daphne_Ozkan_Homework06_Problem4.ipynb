{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "79ee1f38-7e40-4a67-8c82-146b195e3532",
      "metadata": {
        "id": "79ee1f38-7e40-4a67-8c82-146b195e3532"
      },
      "source": [
        "Question 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bad339f-bb26-49f6-848a-6357658a74e0",
      "metadata": {
        "id": "9bad339f-bb26-49f6-848a-6357658a74e0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d78482-870a-4dfc-9a8b-25ddc6b60f21",
      "metadata": {
        "id": "57d78482-870a-4dfc-9a8b-25ddc6b60f21",
        "outputId": "4a83e538-8be4-48e6-af38-98ec14187d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of GPUs = 4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Number of GPUs =\", torch.cuda.device_count())\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae26257f-bde7-46b9-a292-bd3f93db4bd4",
      "metadata": {
        "id": "ae26257f-bde7-46b9-a292-bd3f93db4bd4"
      },
      "outputs": [],
      "source": [
        "def train(trainloader, net, criterion, optimizer):\n",
        "    net.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8564a3eb-c783-4d23-80ca-238c68f1dd9a",
      "metadata": {
        "id": "8564a3eb-c783-4d23-80ca-238c68f1dd9a"
      },
      "outputs": [],
      "source": [
        "def measure_training_time(batch_size):\n",
        "    try:\n",
        "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        net = resnet18(num_classes=10).to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "        # Warm-up\n",
        "        train(trainloader, net, criterion, optimizer)\n",
        "\n",
        "        # Timed run\n",
        "        torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "        train(trainloader, net, criterion, optimizer)\n",
        "        torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "\n",
        "        training_time = end_time - start_time\n",
        "        print(f\"Batch Size: {batch_size}, Training Time: {training_time:.2f} seconds\")\n",
        "        return training_time\n",
        "    except RuntimeError as e:\n",
        "        if 'out of memory' in str(e).lower():\n",
        "            print(f\"Out of memory for batch size: {batch_size}\")\n",
        "            return None\n",
        "        else:\n",
        "            raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c47e2c8-59c6-4c10-8788-c4b33c869c97",
      "metadata": {
        "id": "3c47e2c8-59c6-4c10-8788-c4b33c869c97",
        "outputId": "0dbb36d5-e636-4e12-9d37-45c15e949e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 32, Training Time: 15.51 seconds\n",
            "Batch Size: 128, Training Time: 5.99 seconds\n",
            "Batch Size: 512, Training Time: 5.82 seconds\n",
            "Batch Size: 2048, Training Time: 5.81 seconds\n",
            "Batch Size: 8192, Training Time: 6.19 seconds\n",
            "Batch Size: 32768, Training Time: 9.00 seconds\n",
            "Batch Size: 131072, Training Time: 13.14 seconds\n",
            "Batch Size: 524288, Training Time: 13.02 seconds\n",
            "Batch Size: 2097152, Training Time: 12.90 seconds\n",
            "Batch Size: 8388608, Training Time: 12.97 seconds\n",
            "Batch Size: 33554432, Training Time: 13.03 seconds\n",
            "Batch Size: 134217728, Training Time: 12.90 seconds\n",
            "Batch Size: 536870912, Training Time: 13.16 seconds\n",
            "Batch Size: 2147483648, Training Time: 13.01 seconds\n",
            "Batch Size: 8589934592, Training Time: 13.21 seconds\n",
            "Batch Size: 34359738368, Training Time: 13.09 seconds\n",
            "Batch Size: 137438953472, Training Time: 13.16 seconds\n",
            "Batch Size: 549755813888, Training Time: 13.19 seconds\n",
            "Batch Size: 2199023255552, Training Time: 13.20 seconds\n",
            "Batch Size: 8796093022208, Training Time: 13.17 seconds\n",
            "Batch Size: 35184372088832, Training Time: 13.06 seconds\n",
            "Batch Size: 140737488355328, Training Time: 13.08 seconds\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m times = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     training_time = \u001b[43mmeasure_training_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m training_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      7\u001b[39m         times.append((batch_size, training_time))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mmeasure_training_time\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m      6\u001b[39m optimizer = optim.SGD(net.parameters(), lr=\u001b[32m0.1\u001b[39m, momentum=\u001b[32m0.9\u001b[39m, weight_decay=\u001b[32m5e-4\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Warm-up\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Timed run\u001b[39;00m\n\u001b[32m     12\u001b[39m torch.cuda.synchronize()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(trainloader, net, criterion, optimizer)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(trainloader, net, criterion, optimizer):\n\u001b[32m      2\u001b[39m     net.train()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1458\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data)\n\u001b[32m   1457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1458\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1459\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1420\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1422\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1251\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1239\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1240\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1248\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1254\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1256\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "times = []\n",
        "\n",
        "while True:\n",
        "    training_time = measure_training_time(batch_size)\n",
        "    if training_time is not None:\n",
        "        times.append((batch_size, training_time))\n",
        "        batch_size *= 4\n",
        "    else:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d663ebd5-0e1e-4ad0-beb5-fce76d3623ab",
      "metadata": {
        "id": "d663ebd5-0e1e-4ad0-beb5-fce76d3623ab"
      },
      "source": [
        "To evaluate how training time varies with batch size on a single GPU, I measured the time it takes to complete one timed epoch for progressively increasing batch sizes. I started with a batch size of 32 and increased it by a factor of 4 in each iteration (32, 128, 512, etc.) until the GPU could no longer handle the memory requirements. Each run included two epochs: the first to warm up the cache, and the second for timing. The timing reflects the full training process for one epoch, including data movement to the GPU, gradient computation, and weight updates (but excluding data I/O).\n",
        "\n",
        "In my experiment, the code was executed on a machine with 4 GPUs, but I explicitly configured it to use only a single GPU (cuda:0) to adhere to the instructions. As a result, memory was never exceeded, even for extremely large batch sizes. Since the loop began taking progressively longer to complete at those sizes, I manually interrupted it once the timing values stabilized and were no longer providing additional insight. Training time decreased initially (from batch sizes 32 to 512), then plateaued around sizes like 2048 and 8192, and eventually began increasing again at much larger sizes. This suggests that very small batch sizes underutilize the GPU, while extremely large ones hit diminishing returns and may slow things down. The optimal performance in my case appeared to occur around batch sizes 512 to 2048, where training was fast without incurring additional memory or compute overhead."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1412b2a0-9185-4992-9ed6-dd1dbc469f02",
      "metadata": {
        "id": "1412b2a0-9185-4992-9ed6-dd1dbc469f02"
      },
      "source": [
        "Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57274501-e66d-4483-b0e8-d486c8ae213d",
      "metadata": {
        "id": "57274501-e66d-4483-b0e8-d486c8ae213d"
      },
      "outputs": [],
      "source": [
        "from torch.nn import DataParallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd53b73-6cb8-4a64-90e0-7f5007884e9f",
      "metadata": {
        "id": "4dd53b73-6cb8-4a64-90e0-7f5007884e9f"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(trainloader, net, criterion, optimizer):\n",
        "    net.train()\n",
        "    for inputs, targets in trainloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d449fc-c190-4e08-9ddb-ec29d1318f7e",
      "metadata": {
        "id": "87d449fc-c190-4e08-9ddb-ec29d1318f7e"
      },
      "outputs": [],
      "source": [
        "def measure_training_time(batch_size_per_gpu, num_gpus):\n",
        "    global device\n",
        "    total_batch_size = batch_size_per_gpu * num_gpus\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=total_batch_size,\n",
        "                                              shuffle=True, num_workers=0)\n",
        "\n",
        "    device_ids = list(range(num_gpus))\n",
        "    net = resnet18(num_classes=10)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    net = net.to(device)\n",
        "\n",
        "    if num_gpus > 1:\n",
        "        net = DataParallel(net, device_ids=device_ids)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    train_one_epoch(trainloader, net, criterion, optimizer)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "    train_one_epoch(trainloader, net, criterion, optimizer)\n",
        "    torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    return end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f19311f-8961-451d-8ad8-d2e92a555fc5",
      "metadata": {
        "id": "2f19311f-8961-451d-8ad8-d2e92a555fc5",
        "outputId": "af294f02-2242-4f70-8f4a-46c89dbc146f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size per GPU: 32, GPUs: 1, Time: 25.86 seconds\n",
            "Batch Size per GPU: 32, GPUs: 2, Time: 36.93 seconds\n",
            "Batch Size per GPU: 32, GPUs: 4, Time: 27.25 seconds\n",
            "Batch Size per GPU: 128, GPUs: 1, Time: 14.73 seconds\n",
            "Batch Size per GPU: 128, GPUs: 2, Time: 17.59 seconds\n",
            "Batch Size per GPU: 128, GPUs: 4, Time: 14.82 seconds\n",
            "Batch Size per GPU: 512, GPUs: 1, Time: 11.43 seconds\n",
            "Batch Size per GPU: 512, GPUs: 2, Time: 12.41 seconds\n",
            "Batch Size per GPU: 512, GPUs: 4, Time: 11.78 seconds\n"
          ]
        }
      ],
      "source": [
        "batch_sizes = [32, 128, 512]\n",
        "gpu_counts = [1, 2, 4]\n",
        "\n",
        "results = {}\n",
        "for bs in batch_sizes:\n",
        "    results[bs] = {}\n",
        "    for gpus in gpu_counts:\n",
        "        time_taken = measure_training_time(bs, gpus)\n",
        "        results[bs][gpus] = time_taken\n",
        "        print(f\"Batch Size per GPU: {bs}, GPUs: {gpus}, Time: {time_taken:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a table that records the training time and speedup for different batch sizes up to 4 GPUs:"
      ],
      "metadata": {
        "id": "kfLW_13tkjbD"
      },
      "id": "kfLW_13tkjbD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\"> </th>\n",
        "      <th colspan=\"2\">Batch-size 32 per GPU</th>\n",
        "      <th colspan=\"2\">Batch-size 128 per GPU</th>\n",
        "      <th colspan=\"2\">Batch-size 512 per GPU</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Time (sec)</th>\n",
        "      <th>Speedup</th>\n",
        "      <th>Time (sec)</th>\n",
        "      <th>Speedup</th>\n",
        "      <th>Time (sec)</th>\n",
        "      <th>Speedup</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>1-GPU</td>\n",
        "      <td>25.86</td>\n",
        "      <td>1.00</td>\n",
        "      <td>14.73</td>\n",
        "      <td>1.00</td>\n",
        "      <td>11.43</td>\n",
        "      <td>1.00</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>2-GPU</td>\n",
        "      <td>36.93</td>\n",
        "      <td>1.40</td>\n",
        "      <td>17.59</td>\n",
        "      <td>1.67</td>\n",
        "      <td>12.41</td>\n",
        "      <td>1.84</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>4-GPU</td>\n",
        "      <td>27.25</td>\n",
        "      <td>3.80</td>\n",
        "      <td>14.82</td>\n",
        "      <td>3.97</td>\n",
        "      <td>11.78</td>\n",
        "      <td>3.88</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "y1cFgXCai1B3"
      },
      "id": "y1cFgXCai1B3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Speedup calculation:\n",
        "\n",
        "For 2 GPUs: Speedup = (2 * Time for 1 GPU) / (Time for 2 GPUs)\n",
        "For 4 GPUs: Speedup = (4 * Time for 1 GPU) / (Time for 4 GPUs)"
      ],
      "metadata": {
        "id": "WR3gsVo8kies"
      },
      "id": "WR3gsVo8kies"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This experiment is an example of weak scaling, since we kept the batch size per GPU constant (e.g., 32, 128, etc.) while increasing the number of GPUs. As a result, the total batch size grew with the number of GPUs, and each GPU processed the same amount of data. This setup allows us to observe how well the system handles increased workloads when more GPUs are added.\n",
        "\n",
        "If we had used strong scaling instead, where the total batch size stays constant regardless of the number of GPUs, each GPU would have processed less data as more were added. In that case, we would expect to see even faster training times due to the reduced workload per GPU. However, strong scaling typically runs into diminishing returns, especially when communication overhead between GPUs starts to outweigh the benefits of parallelism."
      ],
      "metadata": {
        "id": "jixjHuz2m2eX"
      },
      "id": "jixjHuz2m2eX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3"
      ],
      "metadata": {
        "id": "HSzesnW8lZ8J"
      },
      "id": "HSzesnW8lZ8J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th rowspan=\"2\"> </th>\n",
        "      <th colspan=\"2\">Batch-size 32 per GPU</th>\n",
        "      <th colspan=\"2\">Batch-size 128 per GPU</th>\n",
        "      <th colspan=\"2\">Batch-size 512 per GPU</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Compute (sec)</th>\n",
        "      <th>Comm (sec)</th>\n",
        "      <th>Compute (sec)</th>\n",
        "      <th>Comm (sec)</th>\n",
        "      <th>Compute (sec)</th>\n",
        "      <th>Comm (sec)</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>2-GPU</td>\n",
        "      <td>12.93</td>\n",
        "      <td>24.00</td>\n",
        "      <td>7.37</td>\n",
        "      <td>10.22</td>\n",
        "      <td>5.72</td>\n",
        "      <td>6.69</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>4-GPU</td>\n",
        "      <td>6.47</td>\n",
        "      <td>20.78</td>\n",
        "      <td>3.68</td>\n",
        "      <td>11.14</td>\n",
        "      <td>2.86</td>\n",
        "      <td>8.92</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "oHN9TVTTl3qi"
      },
      "id": "oHN9TVTTl3qi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have training times for the 1-GPU, 2-GPU, and 4-GPU configurations, we can estimate the compute and communication times for the multi-GPU setups as follows: \\\\\n",
        "\n",
        "* We approximate the compute time for the multi-GPU runs by dividing the 1-GPU training time by the number of GPUs used (i.e., by 2 for 2-GPU and by 4 for 4-GPU setups), assuming ideal scaling with no communication overhead. This is based on the idea that a single GPU does not incur any inter-device communication.\n",
        "\n",
        "* The communication time is then estimated as the difference between the total training time of the multi-GPU setup and its corresponding estimated compute time (i.e., 1-GPU time รท number of GPUs).\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**2-GPU Calculations:**\n",
        "\n",
        "* **Batch size 32:** Compute time = 1-GPU time for batch size 32, which is 25.86 seconds / 2 = 12.93. Communication time would be 36.93 (total time for 2-GPU) - 12.93 = 24.00 sec. \\\\\n",
        "\n",
        "\n",
        "* **Batch size 128:** Compute time is 7.37 seconds. Communication time would be 17.59 - 7.37 = 10.22 sec. \\\\\n",
        "\n",
        "* **Batch size 512:** Compute time is 5.72 seconds. Communication time would be 12.41 - 5.72 = 6.69 sec. \\\\\n",
        "\n",
        "**4-GPU Calculations:**\n",
        "\n",
        "* **Batch size 32:** Compute time = 1-GPU time for batch size 32, which is 25.86 seconds / 4 = 6.47 sec. Communication time would be 27.25 - 6.47 = 20.78 sec. \\\\\n",
        "\n",
        "* **Batch size 128:** Compute time is 3.68 sec. Communication time would be 14.82 - 3.68 = 11.14 sec. \\\\\n",
        "\n",
        "* **Batch size 512:** Compute time is 2.86 sec. Communication time would be 11.78 - 2.86 = 8.92 sec. \\\\"
      ],
      "metadata": {
        "id": "48dex5_xwsgz"
      },
      "id": "48dex5_xwsgz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4"
      ],
      "metadata": {
        "id": "VaOI3NXWlcpB"
      },
      "id": "VaOI3NXWlcpB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The formula for allreaduce is: $2(N-1)(\\frac{K}{N})$,\n",
        "\n",
        "where K is the number of model parameters, and N is the number of GPUs.\n",
        "\n",
        "<br>\n",
        "\n",
        "The formula for bandwidth utilization is: Allreduce cost / Communication time\n",
        "\n",
        "<br>\n",
        "\n",
        "First, we calculate the Allreduce cost for when the number of GPUs is equal to 2 and 4: \\\\\n",
        "\n",
        "We know that the number of parameters in ResNet18 is K = 11,689,512 \\\\\n",
        "\n",
        "* For 2 GPUs: Allreduce cost = $2(2-1)\\frac{11,689,512}{2} = 11,689,512$\n",
        "\n",
        "* For 4 GPUs: Allreduce cost = $2(4-1)\\frac{11,689,512}{4} = 17,534,268$ \\\\\n",
        "\n",
        "Since we want our final r4esults to be in units of (GB/s), we convert the above values to GB: //\n",
        "\n",
        "* For 2 GPUs: Allreduce cost = $\\frac{11,689,512 * 4 bytes}{2^{30}} = 0.044 GB$\n",
        "\n",
        "* For 4 GPUs: Allreduce cost = $\\frac{17,534,268 * 4 bytes}{2^{30}} = 0.065 GB$\n",
        "\n",
        "** 1 GB = $20^{30}$ bytes*\n",
        "\n",
        "<br>\n",
        "\n",
        "To get the Bandwith Utilization, we divide the above values for Allreduce costs with the corresponding communication time from part 3 for each batch size: \\\\\n",
        "\n",
        "\n",
        "\n",
        "<table>\n",
        "<thead>\n",
        "<tr>\n",
        "<th></th>\n",
        "<th>Batch-size-per-GPU 32<br><small>Bandwidth Utilization (GB/s)</small></th>\n",
        "<th>Batch-size-per-GPU 128<br><small>Bandwidth Utilization (GB/s)</small></th>\n",
        "<th>Batch-size-per-GPU 512<br><small>Bandwidth Utilization (GB/s)</small></th>\n",
        "</tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "<tr>\n",
        "<td><strong>2-GPU</strong></td>\n",
        "<td>0.0018</td>\n",
        "<td>0.0043</td>\n",
        "<td>0.0066</td>\n",
        "</tr>\n",
        "<tr>\n",
        "<td><strong>4-GPU</strong></td>\n",
        "<td>0.0031</td>\n",
        "<td>0.0058</td>\n",
        "<td>0.0073</td>\n",
        "</tr>\n",
        "</tbody>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "aH__LdSKl4Oq"
      },
      "id": "aH__LdSKl4Oq"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}